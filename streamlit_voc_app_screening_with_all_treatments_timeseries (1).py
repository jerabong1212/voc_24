import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px

# Stats
import statsmodels.api as sm
import statsmodels.formula.api as smf
from statsmodels.stats.multicomp import MultiComparison

# Optional: Duncan test (via scikit-posthocs)
try:
    import scikit_posthocs as sp
    HAS_SCPH = True
except Exception:
    HAS_SCPH = False

# -------------------------
# ê¸°ë³¸ ì„¤ì •
# -------------------------
st.set_page_config(page_title="VOC ì‹¤í—˜ ì‹œê°í™”", layout="wide")
st.title("ğŸŒ¿ ì‹ë¬¼ VOC ì‹¤í—˜ ê²°ê³¼ ì‹œê°í™”")

# -------------------------
# ë°ì´í„° ë¡œë“œ
# -------------------------
try:
    df = pd.read_excel("VOC_data.xlsx")
except Exception as e:
    st.error(f"ë°ì´í„° ë¡œë”© ì˜¤ë¥˜: {e}")
    st.stop()

# -------------------------
# ì»¬ëŸ¼ëª…(ì—‘ì…€ 1í–‰)
# -------------------------
NAME_COL      = "Name"
TREAT_COL     = "Treatment"
START_COL     = "Start Date"
END_COL       = "End Date"
CHAMBER_COL   = "Chamber"
LINE_COL      = "Line"
PROGRESS_COL  = "Progress"
INTERVAL_COL  = "Interval (h)"
TEMP_COL      = "Temp (â„ƒ)"
HUMID_COL     = "Humid (%)"

# ë°˜ë³µ/ì†Œë°˜ë³µ ìë™ ê°ì§€ (ì—¬ëŸ¬ í‘œê¸° í—ˆìš©)
REP_CANDIDATES    = ["Repetition", "rep", "Rep", "repetition", "ë°˜ë³µ", "ë°˜ë³µìˆ˜"]
SUBREP_CANDIDATES = ["Sub-repetition", "subrep", "Subrep", "Sub-rep", "sub-repetition", "ì†Œë°˜ë³µ", "ì†Œë°˜ë³µìˆ˜"]
REP_COL    = next((c for c in REP_CANDIDATES if c in df.columns), None)
SUBREP_COL = next((c for c in SUBREP_CANDIDATES if c in df.columns), None)

# -------------------------
# VOC 24ì¢… (ì‚¬ìš©ì ì œê³µ)
# -------------------------
VOC_24_CANDIDATES = [
    "(+/-)-trans-nerolidol",
    "(E)-2-hexenal;(Z)-3-hexenal",
    "(S)-citronellol",
    "(Z)-3-hexen-1-ol",
    "(Z)-3-hexenyl acetate",
    "2-phenylethanol",
    "alpha-farnesene",
    "alpha-pinene",
    "benzaldehyde",
    "beta-caryophyllene",
    "beta-pinene",
    "DEN",
    "eucalyptol",
    "indole",
    "lemonol",
    "linalool",
    "methyl jasmonate (20180404ATFtest)",
    "methyl salicylate",
    "nicotine",
    "nitric oxide",
    "ocimene;Limonene;myrcene",
    "Pinenes",
    "toluene",
    "xylenes + ethylbenzene",
]

DISPLAY_MAP = {
    "DEN": "DMNT",
    "DMNT": "DMNT",
    "methyl jasmonate (20180404ATFtest)": "Methyl jasmonate",
    "methyl jasmonate (temporary)": "Methyl jasmonate",
}

def display_name(col):
    return DISPLAY_MAP.get(col, col)


def resolve_voc_columns(df, candidates):
    resolved = []
    for col in candidates:
        if col in df.columns:
            resolved.append(col)
        elif col == "DEN" and "DMNT" in df.columns:
            resolved.append("DMNT")
    return resolved


voc_columns = resolve_voc_columns(df, VOC_24_CANDIDATES)
if len(voc_columns) == 0:
    st.error("VOC ì»¬ëŸ¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. íŒŒì¼ í—¤ë”(24ì¢…) í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤.")
    st.stop()
elif len(voc_columns) < len(VOC_24_CANDIDATES):
    st.info(
        f"ì„¤ì •ëœ 24ì¢… ì¤‘ ë°ì´í„°ì—ì„œ ë°œê²¬í•œ ì»¬ëŸ¼ ìˆ˜: {len(voc_columns)} / {len(VOC_24_CANDIDATES)}
"
        f"ê°ì§€ëœ VOC: {', '.join([display_name(c) for c in voc_columns])}"
    )

# -------------------------
# ì²˜ë¦¬/ì¸í„°ë²Œ/ë°˜ë³µ ëª©ë¡
# -------------------------
if TREAT_COL not in df.columns or INTERVAL_COL not in df.columns:
    st.error(f"í•„ìˆ˜ í‚¤ ì»¬ëŸ¼ ëˆ„ë½: {TREAT_COL}, {INTERVAL_COL}")
    st.stop()

# ê¸°ë³¸ ì²˜ë¦¬êµ¬ ëª©ë¡(ì •ë ¬)
treatments = sorted(df[TREAT_COL].dropna().astype(str).unique().tolist())
# ì‹œê°„ë³„ ëª¨ë“œì—ì„œ ì‚¬ìš©í•  ì˜µì…˜(ì „ì²´ í¬í•¨)
treatments_for_ts = ["ì „ì²´"] + treatments

intervals = sorted(pd.to_numeric(df[INTERVAL_COL], errors="coerce").dropna().unique().tolist())

expected_intervals = [-1, 0, 1, 2, 3, 4, 5, 6, 12, 18, 24]
missing = [x for x in expected_intervals if x not in intervals]
if missing:
    st.info(f"ë°ì´í„°ì— ì—†ëŠ” Interval(h): {missing} (ê¸°ì¤€ ê°„ê²©)")

# ë°˜ë³µìˆ˜ ì˜µì…˜(ìˆì„ ë•Œë§Œ)
reps_all = ["ì „ì²´"] + sorted(df[REP_COL].dropna().astype(str).unique().tolist()) if REP_COL else ["ì „ì²´"]

# -------------------------
# ì‚¬ì´ë“œë°”
# -------------------------
st.sidebar.header("ğŸ”§ ë¶„ì„ ì˜µì…˜")
if CHAMBER_COL not in df.columns or LINE_COL not in df.columns:
    st.warning("Chamber/Line ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ í—¤ë”ë¥¼ í™•ì¸í•˜ì„¸ìš”.")

chambers = ["ì „ì²´"] + sorted(df[CHAMBER_COL].dropna().astype(str).unique().tolist()) if CHAMBER_COL in df.columns else ["ì „ì²´"]
lines    = ["ì „ì²´"] + sorted(df[LINE_COL].dropna().astype(str).unique().tolist()) if LINE_COL in df.columns else ["ì „ì²´"]

chamber_sel = st.sidebar.selectbox("ğŸ  Chamber", chambers, index=0)
line_sel    = st.sidebar.selectbox("ğŸ§µ Line", lines, index=0)

# ë°˜ë³µìˆ˜ ì„ íƒ(ì „ì—­ í•„í„°)
rep_sel = st.sidebar.selectbox("ğŸ” Repetition", reps_all, index=0) if REP_COL else "ì „ì²´"

# ì†Œë°˜ë³µ í‘œì‹œ/ì§‘ê³„ ì˜µì…˜
show_subrep_lines = st.sidebar.checkbox("ì†Œë°˜ë³µ ë¼ì¸ í‘œì‹œ", value=bool(SUBREP_COL)) if SUBREP_COL else False

progress_vals_all = sorted(df[PROGRESS_COL].dropna().astype(str).unique().tolist()) if PROGRESS_COL in df.columns else []
progress_sel = st.sidebar.multiselect("ğŸ§­ Progress(ë³µìˆ˜ ì„ íƒ ê°€ëŠ¥)", progress_vals_all, default=progress_vals_all)

mode = st.sidebar.radio("ë¶„ì„ ëª¨ë“œ ì„ íƒ", ["ì²˜ë¦¬ë³„ VOC ë¹„êµ", "ì‹œê°„ë³„ VOC ë³€í™”", "ì „ì²´ VOC ìŠ¤í¬ë¦¬ë‹"])

# ê³µí†µ VOC ì„ íƒ(ìŠ¤í¬ë¦¬ë‹ ëª¨ë“œëŠ” ë¹„í™œì„±í™”)
if mode != "ì „ì²´ VOC ìŠ¤í¬ë¦¬ë‹":
    selected_voc = st.sidebar.selectbox("ğŸ“Œ VOC ë¬¼ì§ˆ ì„ íƒ", [display_name(c) for c in voc_columns])
    inv_map = {display_name(c): c for c in voc_columns}
    selected_voc_internal = inv_map[selected_voc]
else:
    selected_voc = None
    selected_voc_internal = None

facet_by_chamber = st.sidebar.checkbox("Chamberë¡œ ë¶„í•  ë³´ê¸°", value=False)
facet_by_line    = st.sidebar.checkbox("Lineìœ¼ë¡œ ë¶„í•  ë³´ê¸°", value=False)

# ì˜¤ì°¨ ê¸°ì¤€ ì„ íƒ (SD/SEM)
err_mode = st.sidebar.radio("ì˜¤ì°¨ ê¸°ì¤€", ["SD", "SEM"], index=0)

# -------------------------
# ê³µí†µ: í•„í„° ì ìš©
# -------------------------
filtered_df = df.copy()
if CHAMBER_COL in filtered_df.columns and chamber_sel != "ì „ì²´":
    filtered_df = filtered_df[filtered_df[CHAMBER_COL].astype(str) == str(chamber_sel)]
if LINE_COL in filtered_df.columns and line_sel != "ì „ì²´":
    filtered_df = filtered_df[filtered_df[LINE_COL].astype(str) == str(line_sel)]
if PROGRESS_COL in filtered_df.columns and progress_sel:
    filtered_df = filtered_df[filtered_df[PROGRESS_COL].astype(str).isin(progress_sel)]
if REP_COL and rep_sel != "ì „ì²´":
    filtered_df = filtered_df[filtered_df[REP_COL].astype(str) == str(rep_sel)]

# -------------------------
# ìœ í‹¸
# -------------------------

def add_facets(kwargs, data_frame):
    if facet_by_chamber and CHAMBER_COL in data_frame.columns:
        kwargs["facet_col"] = CHAMBER_COL
    if facet_by_line and LINE_COL in data_frame.columns:
        if "facet_col" in kwargs:
            kwargs["facet_row"] = LINE_COL
        else:
            kwargs["facet_col"] = LINE_COL
    return kwargs


def p_to_stars(p):
    if p < 0.001:
        return "***"
    elif p < 0.01:
        return "**"
    elif p < 0.05:
        return "*"
    else:
        return "ns"


def cld_from_nonsig(groups, pairs_ns):
    groups = list(groups)
    letters = {g: "" for g in groups}
    remaining = set(groups)
    alphabet = list("abcdefghijklmnopqrstuvwxyz")
    li = 0
    while remaining:
        letter = alphabet[li % len(alphabet)]
        bucket = []
        for g in list(remaining):
            ok = True
            for h in bucket:
                pair = tuple(sorted((g, h)))
                if pair not in pairs_ns and g != h:
                    ok = False
                    break
            if ok:
                bucket.append(g)
        for g in bucket:
            letters[g] += letter
            remaining.remove(g)
        li += 1
    for g in groups:
        if letters[g] == "":
            letters[g] = "a"
    return letters


def format_letters_string(letters_dict, treat_order):
    parts = []
    for t in treat_order:
        parts.append(f"{t}={letters_dict.get(str(t), '')}")
    return "; ".join(parts)


def sem_from_sd(sd, n):
    try:
        return sd / np.sqrt(n) if (sd is not None and n and n > 0) else np.nan
    except Exception:
        return np.nan


def attach_error_col(df_stats, err_mode):
    df_stats = df_stats.copy()
    if err_mode == "SEM":
        df_stats["err"] = df_stats.apply(lambda r: sem_from_sd(r.get("sd", np.nan), r.get("n", np.nan)), axis=1)
    else:
        df_stats["err"] = df_stats.get("sd", np.nan)
    return df_stats

# -------------------------
# ì²˜ë¦¬ë³„ VOC ë¹„êµ / ì‹œê°„ë³„ VOC ë³€í™”
# -------------------------
if mode in ["ì²˜ë¦¬ë³„ VOC ë¹„êµ", "ì‹œê°„ë³„ VOC ë³€í™”"]:
    if mode == "ì²˜ë¦¬ë³„ VOC ë¹„êµ":
        chart_type = st.sidebar.radio("ì°¨íŠ¸ ìœ í˜•", ["ë§‰ëŒ€ê·¸ë˜í”„", "ë°•ìŠ¤í”Œë¡¯"], index=0)
        selected_interval = st.sidebar.selectbox("â± Interval (h) ì„ íƒ", ["ì „ì²´"] + intervals)

        show_anova = False
        posthoc_choices = []
        alpha = 0.05
        letters_method_for_plot = None

        if chart_type == "ë§‰ëŒ€ê·¸ë˜í”„":
            show_anova = st.sidebar.checkbox("ANOVA ë¶„ì„ í‘œì‹œ(ë§‰ëŒ€ê·¸ë˜í”„ ì „ìš©)", value=False)
            # ë°˜ë³µì„ ë¸”ë¡ìš”ì¸ìœ¼ë¡œ í¬í•¨ ì˜µì…˜
            include_rep_block = st.sidebar.checkbox("ë°˜ë³µì„ ë¸”ë¡ìš”ì¸ìœ¼ë¡œ í¬í•¨", value=bool(REP_COL)) if REP_COL else False
            if show_anova:
                alpha = st.sidebar.number_input("ìœ ì˜ìˆ˜ì¤€ Î±", min_value=0.001, max_value=0.20, value=0.05, step=0.001, format="%.3f")
                allowed_methods = ["Tukey HSD"]
                if HAS_SCPH:
                    allowed_methods.append("Duncan")
                posthoc_choices = st.sidebar.multiselect("ì‚¬í›„ê²€ì • ì„ íƒ(ë³µìˆ˜ ê°€ëŠ¥)", allowed_methods, default=allowed_methods[:1])
                if len(posthoc_choices) > 0:
                    letters_method_for_plot = st.sidebar.selectbox("ê·¸ë˜í”„ì— í‘œì‹œí•  ìœ ì˜ë¬¸ì ê¸°ì¤€", posthoc_choices, index=0)

    else:  # ì‹œê°„ë³„ VOC ë³€í™”
        # âœ… ì²˜ë¦¬êµ¬ ì„ íƒì— "ì „ì²´" ì˜µì…˜ ì¶”ê°€
        selected_treatment = st.sidebar.selectbox("ğŸ§ª ì²˜ë¦¬êµ¬ ì„ íƒ", treatments_for_ts)

    # ë°ì´í„° subset
    if mode == "ì²˜ë¦¬ë³„ VOC ë¹„êµ":
        if selected_interval == "ì „ì²´":
            data_use = filtered_df.copy()
            title_suffix = "ëª¨ë“  ì‹œê°„"
        else:
            data_use = filtered_df[pd.to_numeric(filtered_df[INTERVAL_COL], errors="coerce") == selected_interval].copy()
            title_suffix = f"Interval: {selected_interval}h"

        y_label = f"{selected_voc} ë†ë„ (ppb)"
        color_kw = {"color": PROGRESS_COL} if (PROGRESS_COL in data_use.columns and data_use[PROGRESS_COL].notna().any()) else {}

        if chart_type == "ë§‰ëŒ€ê·¸ë˜í”„":
            group_keys = [TREAT_COL]
            if PROGRESS_COL in data_use.columns and PROGRESS_COL in data_use:
                group_keys.append(PROGRESS_COL)
            if CHAMBER_COL in data_use.columns and facet_by_chamber:
                group_keys.append(CHAMBER_COL)
            if LINE_COL in data_use.columns and facet_by_line:
                group_keys.append(LINE_COL)

            # ìš”ì•½: (ì†Œë°˜ë³µ í‰ê· ) â†’ (ë°˜ë³µ í‰ê· ) â†’ ì²˜ë¦¬ í‰ê· Â±SD/SEM
            if SUBREP_COL and SUBREP_COL in data_use.columns:
                per_subrep = data_use.groupby(group_keys + [REP_COL] + [SUBREP_COL])[selected_voc_internal].mean().reset_index() if REP_COL else data_use.groupby(group_keys + [SUBREP_COL])[selected_voc_internal].mean().reset_index()
            else:
                per_subrep = data_use.copy()

            if REP_COL and REP_COL in data_use.columns:
                per_rep = per_subrep.groupby(group_keys + [REP_COL])[selected_voc_internal].mean().reset_index()
                grouped = per_rep.groupby(group_keys)[selected_voc_internal].agg(mean="mean", sd="std", n="count").reset_index()
            else:
                grouped = per_subrep.groupby(group_keys)[selected_voc_internal].agg(mean="mean", sd="std", n="count").reset_index()

            grouped = attach_error_col(grouped, err_mode)

            fig_kwargs = dict(
                x=TREAT_COL, y="mean",
                labels={"mean": y_label, TREAT_COL: "ì²˜ë¦¬"},
                title=f"{selected_voc} - ì²˜ë¦¬ë³„ í‰ê·  ë¹„êµ ({title_suffix})",
                **color_kw
            )
            fig_kwargs = add_facets(fig_kwargs, grouped)
            fig = px.bar(grouped, **fig_kwargs, error_y="err", barmode="group")
            fig.update_layout(margin=dict(l=10, r=10, t=60, b=10))

            if show_anova:
                base_cols = [TREAT_COL, selected_voc_internal]
                if REP_COL: base_cols.append(REP_COL)
                anova_df = data_use[base_cols].dropna().copy()
                if anova_df[TREAT_COL].nunique() >= 2 and all(anova_df.groupby(TREAT_COL)[selected_voc_internal].count() >= 2):
                    a_df = anova_df.rename(columns={selected_voc_internal: "y", TREAT_COL: "treat"})
                    try:
                        if include_rep_block and REP_COL and REP_COL in a_df.columns:
                            a_df["rep"] = a_df[REP_COL].astype(str)
                            model = smf.ols("y ~ C(treat) + C(rep)", data=a_df).fit()
                        else:
                            model = smf.ols("y ~ C(treat)", data=a_df).fit()
                    except Exception:
                        model = smf.ols("y ~ C(treat)", data=a_df).fit()
                    anova_table = sm.stats.anova_lm(model, typ=2)

                    pval = np.nan
                    try:
                        pval = float(anova_table.loc["C(treat)", "PR(>F)"])
                    except Exception:
                        for idx in anova_table.index:
                            if "C(treat)" in str(idx) or "treat" == str(idx):
                                pval = float(anova_table.loc[idx, "PR(>F)"])
                                break
                    stars = p_to_stars(pval) if not np.isnan(pval) else "n/a"
                    fig.update_layout(title=f"{selected_voc} - ì²˜ë¦¬ë³„ í‰ê·  ë¹„êµ ({title_suffix})  |  ANOVA: p={pval:.4g} ({stars})")

                    posthoc_letters = {}
                    summary_tables = []
                    means_df = grouped.groupby(TREAT_COL)["mean"].mean().reset_index().rename(columns={"mean":"Mean"})
                    counts = a_df.groupby("treat")["y"].count()
                    means_df["n"] = means_df[TREAT_COL].astype(str).map(counts).fillna(0).astype(int)
                    treat_order = means_df[TREAT_COL].astype(str).tolist()

                    if "Tukey HSD" in posthoc_choices:
                        mc = MultiComparison(a_df["y"], a_df["treat"])
                        tukey = mc.tukeyhsd(alpha=alpha)
                        tukey_df = pd.DataFrame(tukey._results_table.data[1:], columns=tukey._results_table.data[0])
                        ns_pairs = set()
                        for _, row in tukey_df.iterrows():
                            g1, g2, reject = str(row["group1"]), str(row["group2"]), bool(row["reject"])
                            if not reject:
                                ns_pairs.add(tuple(sorted((g1, g2))))
                        for g in treat_order:
                            ns_pairs.add((g, g))
                        letters = cld_from_nonsig(treat_order, ns_pairs)
                        posthoc_letters["Tukey HSD"] = letters

                        letters_list = [letters.get(str(g), "") for g in means_df[TREAT_COL]]
                        tukey_summary = means_df.copy()
                        tukey_summary["Letters (Tukey)"] = letters_list
                        summary_tables.append(("Tukey HSD", tukey_summary))

                        st.subheader("Tukey HSD (ì‚¬í›„ê²€ì •)")
                        st.dataframe(tukey_df)
                        st.download_button(
                            "â¬‡ï¸ Tukey HSD í…Œì´ë¸” CSV",
                            data=tukey_df.to_csv(index=False).encode("utf-8-sig"),
                            file_name="tukey_hsd_results.csv",
                            mime="text/csv",
                        )

                    if "Duncan" in posthoc_choices:
                        if HAS_SCPH:
                            try:
                                duncan_mat = sp.posthoc_duncan(a_df, val_col="y", group_col="treat", alpha=alpha)
                                ns_pairs = set()
                                for g1 in duncan_mat.index.astype(str):
                                    for g2 in duncan_mat.columns.astype(str):
                                        if g1 == g2:
                                            ns_pairs.add(tuple(sorted((g1, g2))))
                                        else:
                                            p = duncan_mat.loc[g1, g2]
                                            if pd.isna(p) or p >= alpha:
                                                ns_pairs.add(tuple(sorted((g1, g2))))
                                letters = cld_from_nonsig(treat_order, ns_pairs)
                                posthoc_letters["Duncan"] = letters

                                letters_list = [letters.get(str(g), "") for g in means_df[TREAT_COL]]
                                duncan_summary = means_df.copy()
                                duncan_summary["Letters (Duncan)"] = letters_list
                                summary_tables.append(("Duncan", duncan_summary))

                                st.subheader("Duncan (ì‚¬í›„ê²€ì •) p-value í–‰ë ¬")
                                st.dataframe(duncan_mat)
                                st.download_button(
                                    "â¬‡ï¸ Duncan p-value ë§¤íŠ¸ë¦­ìŠ¤ CSV",
                                    data=duncan_mat.to_csv().encode("utf-8-sig"),
                                    file_name="duncan_posthoc_pvals.csv",
                                    mime="text/csv",
                                )
                            except Exception as e:
                                st.warning(f"Duncan ì‚¬í›„ê²€ì • ê³„ì‚° ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
                        else:
                            st.info("Duncan ì‚¬í›„ê²€ì •ì„ ì‚¬ìš©í•˜ë ¤ë©´ scikit-posthocs íŒ¨í‚¤ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤. (requirementsì— 'scikit-posthocs' ì¶”ê°€)")

                    # letters ê·¸ë˜í”„ í‘œì‹œ (facet ë¯¸ì‚¬ìš© ì‹œ)
                    if letters_method_for_plot and (not facet_by_chamber) and (not facet_by_line):
                        letters_to_use = posthoc_letters.get(letters_method_for_plot, None)
                        if letters_to_use:
                            cat_ymax = {}
                            for tr in fig.data:
                                if getattr(tr, "type", "") == "bar":
                                    xs = list(getattr(tr, "x", []) or [])
                                    ys = list(getattr(tr, "y", []) or [])
                                    for xval, yval in zip(xs, ys):
                                        if xval is None or yval is None:
                                            continue
                                        key = str(xval)
                                        if key not in cat_ymax or yval > cat_ymax[key]:
                                            cat_ymax[key] = float(yval)
                            for xcat, yval in cat_ymax.items():
                                letter = letters_to_use.get(str(xcat), "")
                                if letter:
                                    fig.add_annotation(x=xcat, y=yval, text=letter, showarrow=False, yshift=12, font=dict(size=14))

                    st.subheader("ANOVA ê²°ê³¼")
                    st.dataframe(anova_table)
                    if summary_tables:
                        st.subheader("ì‚¬í›„ê²€ì • ìš”ì•½ (í‰ê·  + Letters)")
                        for label, tbl in summary_tables:
                            st.markdown(f"**{label}**")
                            st.dataframe(tbl)
                    st.download_button(
                        "â¬‡ï¸ ANOVA í…Œì´ë¸” CSV",
                        data=anova_table.to_csv().encode("utf-8-sig"),
                        file_name="anova_results.csv",
                        mime="text/csv",
                    )
                else:
                    st.info("ANOVAë¥¼ ìˆ˜í–‰í•˜ê¸° ìœ„í•œ í‘œë³¸ ìˆ˜ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. (ì²˜ë¦¬ ìˆ˜ì¤€ â‰¥2, ê° ì²˜ë¦¬ nâ‰¥2 ê¶Œì¥)")

            st.plotly_chart(fig, use_container_width=True)

        else:  # ë°•ìŠ¤í”Œë¡¯
            # ë°•ìŠ¤í”Œë¡¯ì€ ê¸°ë³¸ì ìœ¼ë¡œ ì›ìë£Œ ë¶„í¬ë¥¼ ë³´ì—¬ì¤Œ. í•„ìš” ì‹œ ë°˜ë³µ í‰ê·  ê¸°ë°˜ ìš”ì•½ ì˜µì…˜ ì œê³µ
            use_rep_agg_box = st.sidebar.checkbox("ë°•ìŠ¤í”Œë¡¯ë„ ë°˜ë³µ í‰ê·  ê¸°ë°˜ìœ¼ë¡œ ìš”ì•½", value=False) if REP_COL else False
            if use_rep_agg_box and REP_COL:
                group_keys_box = [TREAT_COL]
                if PROGRESS_COL in data_use.columns:
                    group_keys_box.append(PROGRESS_COL)
                if CHAMBER_COL in data_use.columns and facet_by_chamber:
                    group_keys_box.append(CHAMBER_COL)
                if LINE_COL in data_use.columns and facet_by_line:
                    group_keys_box.append(LINE_COL)
                if SUBREP_COL and SUBREP_COL in data_use.columns:
                    per_subrep_box = data_use.groupby(group_keys_box + [REP_COL, SUBREP_COL])[selected_voc_internal].mean().reset_index()
                else:
                    per_subrep_box = data_use.groupby(group_keys_box + [REP_COL])[selected_voc_internal].mean().reset_index()
                per_rep_box = per_subrep_box.groupby(group_keys_box + [REP_COL])[selected_voc_internal].mean().reset_index()
                data_for_box = per_rep_box
                y_for_box = selected_voc_internal
            else:
                data_for_box = data_use
                y_for_box = selected_voc_internal
            fig_kwargs = dict(
                x=TREAT_COL, y=y_for_box,
                labels={y_for_box: y_label, TREAT_COL: "ì²˜ë¦¬"},
                title=f"{selected_voc} - ì²˜ë¦¬ë³„ ë¶„í¬ (ë°•ìŠ¤í”Œë¡¯) ({title_suffix})",
                points="outliers",
                **color_kw,
            )
            fig_kwargs = add_facets(fig_kwargs, data_for_box)
            fig = px.box(data_for_box, **fig_kwargs)
            fig.update_layout(margin=dict(l=10, r=10, t=60, b=10))
            st.plotly_chart(fig, use_container_width=True)

    else:  # ì‹œê°„ë³„ VOC ë³€í™”
        # âœ… ì „ì²´ ì„ íƒ ì‹œ: ëª¨ë“  ì²˜ë¦¬êµ¬ í¬í•¨
        if selected_treatment == "ì „ì²´":
            data_use = filtered_df.copy()
            title_prefix = "ëª¨ë“  ì²˜ë¦¬"
        else:
            data_use = filtered_df[filtered_df[TREAT_COL].astype(str) == str(selected_treatment)].copy()
            title_prefix = f"{selected_treatment} ì²˜ë¦¬"

        tick_vals = expected_intervals

        # í‘œì‹œìš© ê·¸ë£¹í‚¤ êµ¬ì„±
        group_keys_display = [INTERVAL_COL]
        if selected_treatment == "ì „ì²´":
            group_keys_display.append(TREAT_COL)
        if PROGRESS_COL in data_use.columns:
            group_keys_display.append(PROGRESS_COL)
        if CHAMBER_COL in data_use.columns and facet_by_chamber:
            group_keys_display.append(CHAMBER_COL)
        if LINE_COL in data_use.columns and facet_by_line:
            group_keys_display.append(LINE_COL)

        # ì§‘ê³„ ë¡œì§: ë°˜ë³µì´ 2ê°œ ì´ìƒì´ë©´ 'ë°˜ë³µ ê°„' í‰ê· Â±ì˜¤ì°¨, ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ 'ì†Œë°˜ë³µ ê°„' í‰ê· Â±ì˜¤ì°¨
        n_rep = data_use[REP_COL].nunique() if REP_COL and REP_COL in data_use.columns else 0

        if SUBREP_COL and SUBREP_COL in data_use.columns:
            per_subrep_ts = data_use.groupby(group_keys_display + (([REP_COL] if REP_COL else []) + [SUBREP_COL]))[selected_voc_internal].mean().reset_index()
        else:
            per_subrep_ts = data_use.copy()

        if n_rep and n_rep >= 2:
            # 1) ì†Œë°˜ë³µ â†’ ë°˜ë³µ í‰ê· , 2) ë°˜ë³µ ê°„ í‰ê· Â±ì˜¤ì°¨
            per_rep_ts = per_subrep_ts.groupby(group_keys_display + [REP_COL])[selected_voc_internal].mean().reset_index()
            final = per_rep_ts.groupby(group_keys_display)[selected_voc_internal].agg(mean="mean", sd="std", n="count").reset_index().sort_values(INTERVAL_COL)
            err_basis = "ë°˜ë³µ SD/SEM"
        else:
            # ë°˜ë³µ 1ê°œ ì´í•˜: ì†Œë°˜ë³µ ê°„ í‰ê· Â±ì˜¤ì°¨
            final = per_subrep_ts.groupby(group_keys_display)[selected_voc_internal].agg(mean="mean", sd="std", n="count").reset_index().sort_values(INTERVAL_COL)
            err_basis = "ì†Œë°˜ë³µ SD/SEM"

        final = attach_error_col(final, err_mode)

        fig_kwargs = dict(
            x=INTERVAL_COL,
            y="mean",
            error_y="err",
            markers=True,
            labels={INTERVAL_COL: "Interval (h)", "mean": f"{selected_voc} í‰ê· ë†ë„ (ppb)"},
            title=f"{title_prefix} - {selected_voc} ë³€í™” ì¶”ì´ (í‰ê· Â±{err_mode}, ê¸°ì¤€: {err_basis})",
        )
        if selected_treatment == "ì „ì²´":
            fig_kwargs["color"] = TREAT_COL
        elif PROGRESS_COL in data_use.columns:
            fig_kwargs["color"] = PROGRESS_COL
        fig_kwargs = add_facets(fig_kwargs, final)
        fig_voc = px.line(final, **fig_kwargs)
        fig_voc.update_xaxes(tickmode='array', tickvals=tick_vals)
        fig_voc.update_layout(margin=dict(l=10, r=10, t=60, b=10))
        st.plotly_chart(fig_voc, use_container_width=True)

        # ì†Œë°˜ë³µ ë¼ì¸ ì˜¤ë²„ë ˆì´(ì˜µì…˜)
        if show_subrep_lines and SUBREP_COL and SUBREP_COL in data_use.columns:
            # ìƒ‰ìƒ/íŒ¨ì‹¯ í‚¤ ë™ì¼ ìœ ì§€
            disp_cols = group_keys_display.copy()
            disp_df = per_subrep_ts.rename(columns={selected_voc_internal: "val"})
            fig_kwargs_sub = dict(
                x=INTERVAL_COL,
                y="val",
                hover_data=[SUBREP_COL] + ([REP_COL] if REP_COL else []),
                opacity=0.35,
            )
            if selected_treatment == "ì „ì²´":
                fig_kwargs_sub["color"] = TREAT_COL
            elif PROGRESS_COL in data_use.columns:
                fig_kwargs_sub["color"] = PROGRESS_COL
            fig_kwargs_sub = add_facets(fig_kwargs_sub, disp_df)
            fig_sub = px.line(disp_df, **fig_kwargs_sub)
            fig_sub.update_traces(line=dict(width=1))
            st.plotly_chart(fig_sub, use_container_width=True)

        # í™˜ê²½ ë³€ìˆ˜(ì˜¨ë„/ìŠµë„)ë„ ë™ì¼ ë¡œì§ ì ìš©
        cols_exist = [c for c in [TEMP_COL, HUMID_COL] if c in data_use.columns]
        if cols_exist:
            for env_col in cols_exist:
                group_keys_env_disp = group_keys_display.copy()
                if SUBREP_COL and SUBREP_COL in data_use.columns:
                    per_subrep_env = data_use.groupby(group_keys_env_disp + (([REP_COL] if REP_COL else []) + [SUBREP_COL]))[env_col].mean().reset_index()
                else:
                    per_subrep_env = data_use.copy()

                if n_rep and n_rep >= 2:
                    per_rep_env = per_subrep_env.groupby(group_keys_env_disp + ([REP_COL] if REP_COL else []))[env_col].mean().reset_index()
                    ts_env = per_rep_env.groupby(group_keys_env_disp)[env_col].agg(mean="mean", sd="std", n="count").reset_index().sort_values(INTERVAL_COL)
                    err_basis_env = "ë°˜ë³µ SD/SEM"
                else:
                    ts_env = per_subrep_env.groupby(group_keys_env_disp)[env_col].agg(mean="mean", sd="std", n="count").reset_index().sort_values(INTERVAL_COL)
                    err_basis_env = "ì†Œë°˜ë³µ SD/SEM"

                ts_env = attach_error_col(ts_env, err_mode)

                ylab = "ì˜¨ë„ (Â°C)" if env_col == TEMP_COL else "ìƒëŒ€ìŠµë„ (%)" if env_col == HUMID_COL else env_col
                fig_kwargs_env = dict(
                    x=INTERVAL_COL,
                    y="mean",
                    error_y="err",
                    markers=True,
                    labels={INTERVAL_COL: "Interval (h)", "mean": ylab},
                    title=f"{title_prefix} - {env_col} ë³€í™” ì¶”ì´ (í‰ê· Â±{err_mode}, ê¸°ì¤€: {err_basis_env})",
                )
                if selected_treatment == "ì „ì²´":
                    fig_kwargs_env["color"] = TREAT_COL
                elif PROGRESS_COL in data_use.columns:
                    fig_kwargs_env["color"] = PROGRESS_COL

                fig_kwargs_env = add_facets(fig_kwargs_env, ts_env)

                fig_env = px.line(ts_env, **fig_kwargs_env)
                fig_env.update_xaxes(tickmode='array', tickvals=tick_vals)
                fig_env.update_layout(margin=dict(l=10, r=10, t=60, b=10))
                st.plotly_chart(fig_env, use_container_width=True)
        else:
            st.info("ì˜¨ë„/ìƒëŒ€ìŠµë„ ì»¬ëŸ¼ì´ ì—†ì–´ í™˜ê²½ë³€í™” ê·¸ë˜í”„ëŠ” í‘œì‹œí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

# -------------------------
# NEW: ì „ì²´ VOC ìŠ¤í¬ë¦¬ë‹
# -------------------------
elif mode == "ì „ì²´ VOC ìŠ¤í¬ë¦¬ë‹":
    st.subheader("ğŸ” ì „ì²´ VOC ìŠ¤í¬ë¦¬ë‹ (ANOVA ì¼ê´„ ë¶„ì„)")

    selected_interval = st.sidebar.selectbox("â± Interval (h) ì„ íƒ", ["ì „ì²´"] + intervals, key="scr_interval")
    alpha = st.sidebar.number_input("ìœ ì˜ìˆ˜ì¤€ Î±", min_value=0.001, max_value=0.20, value=0.05, step=0.001, format="%.3f", key="scr_alpha")
    do_posthoc = st.sidebar.checkbox("ì‚¬í›„ê²€ì •(Tukey/Duncan) ìš”ì•½ í¬í•¨", value=True)
    posthoc_method = st.sidebar.selectbox("ì‚¬í›„ê²€ì • ë°©ë²•", ["Tukey HSD"] + (["Duncan"] if HAS_SCPH else []), index=0)
    only_sig = st.sidebar.checkbox("ìœ ì˜ VOCë§Œ í‘œì‹œ (p < Î±)", value=False)
    show_letters_cols = st.sidebar.checkbox("Letters ìš”ì•½ ë¬¸ìì—´ í¬í•¨", value=True)
    # ë°˜ë³µì„ ë¸”ë¡ìš”ì¸ìœ¼ë¡œ í¬í•¨ ì˜µì…˜(ìŠ¤í¬ë¦¬ë‹ ê³µí†µ)
    include_rep_block_scr = st.sidebar.checkbox("ë°˜ë³µì„ ë¸”ë¡ìš”ì¸ìœ¼ë¡œ í¬í•¨(ìŠ¤í¬ë¦¬ë‹)", value=bool(REP_COL)) if REP_COL else False

    # Interval í•„í„°
    if selected_interval == "ì „ì²´":
        data_use = filtered_df.copy()
        title_suffix = "ëª¨ë“  ì‹œê°„"
    else:
        data_use = filtered_df[pd.to_numeric(filtered_df[INTERVAL_COL], errors="coerce") == selected_interval].copy()
        title_suffix = f"Interval: {selected_interval}h"

    results = []
    # ê° VOCì— ëŒ€í•´ ANOVA ìˆ˜í–‰
    for voc in voc_columns:
        base_cols = [TREAT_COL, voc]
        if REP_COL: base_cols.append(REP_COL)
        if SUBREP_COL: base_cols.append(SUBREP_COL)
        sub = data_use[base_cols].dropna().copy()
        if sub.empty or sub[TREAT_COL].nunique() < 2:
            continue
        # ê° ì²˜ë¦¬ ìµœì†Œ n>=2 ì²´í¬
        if not all(sub.groupby(TREAT_COL)[voc].count() >= 2):
            continue
        a_df = sub.rename(columns={voc: "y", TREAT_COL: "treat"})
        try:
            if include_rep_block_scr and REP_COL and REP_COL in a_df.columns:
                a_df["rep"] = a_df[REP_COL].astype(str)
                model = smf.ols("y ~ C(treat) + C(rep)", data=a_df).fit()
            else:
                model = smf.ols("y ~ C(treat)", data=a_df).fit()
            anova_table = sm.stats.anova_lm(model, typ=2)
            pval = float(anova_table.loc["C(treat)", "PR(>F)"])
            stars = p_to_stars(pval)
        except Exception:
            pval, stars = np.nan, "ERR"

        letters_str = ""
        if do_posthoc and np.isfinite(pval):
            treat_order = sorted(a_df["treat"].astype(str).unique().tolist())
            if posthoc_method == "Tukey HSD":
                mc = MultiComparison(a_df["y"], a_df["treat"])
                tukey = mc.tukeyhsd(alpha=alpha)
                tukey_df = pd.DataFrame(tukey._results_table.data[1:], columns=tukey._results_table.data[0])
                ns_pairs = set()
                for _, row in tukey_df.iterrows():
                    g1, g2, reject = str(row["group1"]), str(row["group2"]), bool(row["reject"])
                    if not reject:
                        ns_pairs.add(tuple(sorted((g1, g2))))
                for g in treat_order:
                    ns_pairs.add((g, g))
                letters = cld_from_nonsig(treat_order, ns_pairs)
                if show_letters_cols:
                    letters_str = format_letters_string(letters, treat_order)
            elif posthoc_method == "Duncan" and HAS_SCPH:
                try:
                    duncan_mat = sp.posthoc_duncan(a_df, val_col="y", group_col="treat", alpha=alpha)
                    ns_pairs = set()
                    for g1 in duncan_mat.index.astype(str):
                        for g2 in duncan_mat.columns.astype(str):
                            if g1 == g2:
                                ns_pairs.add(tuple(sorted((g1, g2))))
                            else:
                                p = duncan_mat.loc[g1, g2]
                                if pd.isna(p) or p >= alpha:
                                    ns_pairs.add(tuple(sorted((g1, g2))))
                    letters = cld_from_nonsig(treat_order, ns_pairs)
                    if show_letters_cols:
                        letters_str = format_letters_string(letters, treat_order)
                except Exception as e:
                    letters_str = f"Duncan err: {e}"

        results.append({
            "VOC": display_name(voc),
            "p_value": pval,
            "Significance": stars,
            "Letters": letters_str,
        })

    if not results:
        st.info("ì¡°ê±´ì— ë§ëŠ” ë°ì´í„°ê°€ ì—†ì–´ ìŠ¤í¬ë¦¬ë‹ ê²°ê³¼ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. í•„í„°/Interval/Progressë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    else:
        res_df = pd.DataFrame(results)
        res_df = res_df.sort_values("p_value", na_position="last")
        if only_sig:
            res_df = res_df[res_df["p_value"] < alpha]
        st.markdown(f"**Interval: {title_suffix}**, Î±={alpha}")
        st.dataframe(res_df, use_container_width=True)
        st.download_button(
            "â¬‡ï¸ ìŠ¤í¬ë¦¬ë‹ ê²°ê³¼ CSV",
            data=res_df.to_csv(index=False).encode("utf-8-sig"),
            file_name="voc_screening_results.csv",
            mime="text/csv",
        )

# -------------------------
# ì›ë³¸ ë°ì´í„° í™•ì¸
# -------------------------
with st.expander("ğŸ” ì›ë³¸ ë°ì´í„° ë³´ê¸°"):
    st.dataframe(df, use_container_width=True)
